\documentclass[a4paper,12pt]{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[all]{xy}
\usepackage{amsmath,amssymb}

\title{Identifying loci under selective pressure using a PPP-value classifier}
\author{Toby Dylan Hocking}

\begin{document}

\maketitle

\newcommand{\fig}[3][1]{
  \begin{figure}[htp]
    \begin{center}          %linewidth
    \includegraphics[width=#1\textwidth]{#2}
    \end{center}
    \caption{#3\label{#2}}
  \end{figure}
}
% \brat = brace matrix
\newcommand{\brat}[2]{
  \left[
    \begin{array}{#1}
      #2
    \end{array}
    \right]
}
\newcommand{\neff}{\text{popsize}}
\newcommand{\aij}{\alpha_{ij}(t)}
\newcommand{\aijs}{\alpha_{ij}^*(t)}
\newcommand{\wij}[1]{w_{ij}^{\text{#1}}}
\newcommand{\etal}{\emph{et al.}}
\newcommand{\RR}{\mathbb R}
\newcommand{\Bin}{\operatorname{Binomial}}

\section{Introduction}

The explosion of molecular marker data in animal populations from
technologies such as Single Nucleotide Polymorphism (SNP) microarrays
opens new avenues of research for population genetics. These data
allow testing of many aspects of our current models of population
genetics, such as the evolutionary status of these markers relative to
selective pressures. One area we are interested in is the estimation
of genetic differentiation between populations, and establishing
methods for determining which markers and genomic regions have been
under selective pressure. Genomic areas under selection are areas with
probable functional significance, thus the goal is to develop methods
we can use to identify functional genes and augment the current state
of functional annotations for domestic animal genomes.

In the last several decades, the statistical tools of biologists and
geneticists have evolved considerably. In particular, modern computers
and stochastic methods such as Markov Chain Monte Carlo (MCMC) allow
for complex Bayesian models of evolutionary systems. In this work, we
investigate one such Bayesian model used to describe evolution of
domestic animation populations, and extend it with a classifier for
markers under selection.

The model of domestic animal evolution that we consider in this work
is the hierarchical Bayesian model of Nicholson \etal
(2002)\cite{nicholson}, hereafter referred to as the Nicholson
model. This model attempts to estimate ancestral population allele
frequencies for each marker, and a measure of divergence for each
population which is analogous to the classical $F_{st}$ of population
genetics.

The new idea put forth in this work is a classifier for markers under
selection, based on Posterior Predictive P-values
(PPP-values)\cite{pppvalues}. Essentially these PPP-values are the
Bayesian analogue of the usual frequentist P-values, which indicate
departures from the model hypotheses. The Nicholson model was designed
for, and accurately models, independently evolution populations under
genetic drift. However, loci under selection in addition to genetic
drift represent departures from the model hypotheses. Thus we use
PPP-values estimates from the model to identify these aberrent loci.

Furthermore, we validate the model using a simulation of evolution by
genetic drift and selection. The simulator has been implemented using
the R programming language\cite{R}. The model fitting has been
implemented using compiled FORTRAN code dynamically linked to R. The
simulations, analyses, and graphics discussed in this article can be
reproduced by using the code published in the R package
\texttt{nicholsonppp} on R-Forge\cite{R-Forge}:

 \url{http://nicholsonppp.r-forge.r-project.org/}

\section{Methods}

\subsection{Simulating genetic drift and selection}

To simulate selection and genetic drift in several independent
populations, we use a modified version of the simulator in
\cite{Beaumont-Balding}. We assume $L$ independent loci, and $P$
independent populations, evolving over $T$ generations. To model SNP
data, each locus has only 2 possible alleles, thus we denote the
allele frequency for locus $i$ in population $j$ at generation $t$ as
$\aij$, with $0\leq \aij\leq 1$. To assign ancestral allele
frequencies $\pi_i=\alpha_{1,j}(1)=...=\alpha_{L,j}(1)$, we draw from a truncated
$\beta(0.7,0.7)$ distribution \autoref{beta}.

\fig[0.5]{beta}{Distribution of ancestral allele frequencies in our
  simulations follow a truncated $\beta(0.7,0.7)$ distribution.}

If we assign the colors blue and red to the 2 alleles, and we define
$\aij$ is the blue allele frequency, then $1-\aij$ is the red allele
frequency. The color of the allele will determine its fate under
selection in populations which each have a background color of either
red or blue. Population color is chosen at random, independently for
each locus, at the beginning of the simulation, with probability 0.4
for each of red or blue, and 0.2 for neutral populations where neither
allele is favored. The idea is to simulate the fact that some alleles
are favored in some environments, while disfavored in others. Thus,
under positive selection, red alleles will be favored in red
populations, and disfavored in blue populations (vice versa for blue
alleles). Under balancing selection, it is advantageous to have both a
blue and red allele. This simulates the heterozygote advantage, a
phenomenon classically observed in the gene that controls malaria
resistence and sickle-cell anemia affectation.

The allele frequency changes in each generation via
2 mechanisms: drift and selection. Drift introduces some random
variability up or down in allele frequency, independent of population
color:
$$\aijs = \operatorname{rbinom}(\neff,\alpha_{ij}(t-1))$$
The effect of drift grows more important relative to selection as
population size $\neff$ diminishes.

Then to update the allele frequency for selection, we first calculate
relative fitness of each diploid genotype. Relative fitness of a locus
is based on the selection coefficient for that locus $s_i\in \RR$,
which is a parameter of the simulation, usually between 0 and 1 in
empirical studies. Selection for a locus grows more important relative
to genetic drift as $s_i$ increases.
$$
\begin{array}{cccll}
\wij{BB} & \wij{BR} & \wij{RR} & \text{selection type} & \text{population color}\\
\hline
1 & 1+s_i/2 & 1+s_i & \text{positive}& \text{red}\\
1+s_i & 1+s_i/2 & 1 & \text{positive}& \text{blue}\\
1 & 1+s_i & 1 & \text{balancing}& \\
1 & 1 & 1 & \text{neutral}& 
\end{array}
$$
Then we update blue allele frequency for selection based on
Hardy-Weinberg equilibrium:
$$\aij = \frac{
\wij{BB}\aijs^2 + \wij{BR}\aijs[1-\aijs]/2 }{
\wij{BB}\aijs^2 + \wij{BR}\aijs[1-\aijs] + \wij{RR}[1-\aijs]^2
   }$$

   We repeat the process for $t=2, ..., T$, and we take values
   $\alpha_{ij}(T)$ as the output allele frequencies of the
   simulation.



\subsection{The hierarchical bayesian Nicholson model}

To model the variation between observed allele frequencies in
different populations, the Nicholson model assigns a divergence
parameter $c_j$ to each population. The number of observed alleles is
modeled as $x_{ij}\sim \Bin(\neff,\alpha_{ij})$, where $\alpha_{ij}$
is the population allele frequency for locus $i$ and population
$j$. This quantity is in turned modeled by $\alpha_{ij}\sim N(\pi_i,
c_j \pi_i(1-\pi_i))$, a normal distribution truncated to the interval
[0,1]. The differentiation parameter $c_j$ is motivated by population
genetics \cite[section 2.2]{nicholson}. The distributions of the
hyperparameter for ancestral allele frequency follows $\pi_i\sim
\beta(a,a)$ and the population divergence parameter follows $c_j\sim
U[0,1]$.

The relationship between model parameters is more clearly summarised
in the following diagram:

$$
\xymatrix{
  \pi_i \ar[rd] & & c_j \ar[ld] \\
  & \alpha_{ij} \ar[d] & \\
  & (X_{ij},N_{ij})
}
$$

MCMC techniques are used to sample from the following posterior distributions:
$$\alpha^t = P(\alpha|c^{t-1},\pi^{t-1},x)$$
$$\pi^t = P(\pi|c^{t-1},\alpha^t,a)$$
$$c^t = P(c|\pi^t,\alpha^t)$$

\subsection{PPP-value calculation}

Calculation of PPP-values in the Markov Chain is used for the
classifier. For each iteration $t$ through the chain, we say the data fits
the model if the following criterion is met:

$$
p_i^t =
\begin{cases}
1 & \text{if }\left(
\frac{\operatorname{rbinom}(N_{ij},\alpha_{ij}^t)}{N_{ij}} - \pi_i^t
\right)^2
>
\left(
\frac{Y_{ij}}{N_{ij}} - \pi_i^t
\right)^2\\
0 & \text{otherwise}
\end{cases}
$$

Thus the PPP-value for locus $i$ is given by

$$
p_i = \frac 1 T \sum_{t=1}^T p_i^t
$$

\section{Results}

\subsection{Simulation verification}

After obtaining allele frequencies from the simulator, we can do
diagnostic plots to visually verify that the allele frequencies are
evolving according to the theoretical evolution framework we had
envisioned. R packages lattice and ggplot2 are used to visualize these
multivariate data \cite{lattice,ggplot2}.

First, we checked how allele frequencies evolve over time for just a
few loci (\autoref{loci-over-time}). The loci examined show no signs
of departure from the hypotheses of our evolution simulator.

\fig{loci-over-time}{Allele frequency evolution of 6 loci in 12
  populations over 100 generations. Each panel represents a different
  locus, and each line therein represents a different
  population. Shown are two loci for balancing selection (left), no
  selection (middle), and positive selection (right).}

However, to verify that all loci behave according to expectations, we
used dotplots of final allele frequency
(\autoref{fixation-endpoints}). These dotplots efficiently show that
the loci evolved according to the simulator hypotheses.

\fig{fixation-endpoints}{Final simulated blue allele frequency for
  1000 loci and 12 populations is shown in a dotplot. Loci are ordered
  on the horizontal axis by ancestral allele frequency, and then
  divided into 3 panels by selection state. Note that loci under
  selection display no signs of selective pressure when in neutral
  color populations. Inversely, all loci which are not under selection
  behave similarly, regardless of population color. Also, the symmetry
  between blue and red alleles is clearly visible.}

\subsection{Characterization of loci fixation on model fit}

The dotplots above also clearly show that the loci under selection
tend to get fixed at frequencies of 0 or 1 by the end of the
simulation. These data seem to violate the initial hypothesis that we
are dealing with SNP data. That is, data from SNP microarrays is
necessarily biased to favor loci which we have already observed are
polymorphic. This phenomenon is called the ``recruitment bias'' in the
literature.

To characterize if the model estimates are sensitive to the
recruitment bias, we fit several models using non-fixed subsets of the
loci. The criteria used for calling a locus ``fixed'' are as follows:
\begin{description}
\item[not.all.fixed] Throw out the locus if all subpopulations fixed
  (more stringent criterion; less loci will be ``fixed'').
\item[none.fixed] Throw out the locus if one or more subpopulations
  fixed (less stringent criterion; more loci will be ``fixed'').
\end{description}

\fig{fixation-selection}{Percent of loci left after throwing out
  ``fixed'' loci, according to 2 criteria outlined in the text. Note
  how loci under strong positive selection are the loci which get
  excluded.}

To evaluate the effect of throwing out these loci on the total number
of loci left for input to the model, we made scatterplots of percent
of loci ``not fixed'' versus selection strength $s_i$
(\autoref{fixation-selection}). Essentially this told us that loci
under strong positive selection tend to be the ones which get called
``fixed'' and excluded from the model.

\fig{fixed}{Scatterplots of estimated and simulated ancestral allele
  frequency. The Nicholson model was fit for all loci, and 2 subsets
  of loci which were ``not fixed'' (see text). Also shown are large
  and small proportions of neutral loci. Note that the model estimates
  behave similarly regardless of the number of loci included in the
  model.}

To examine if there are any large differences between model estimates
when fixed data are not included, we made scatterplots of estimated
versus simulated ancestral allele frequency $\pi_i$ values
(\autoref{fixed}). This plot indicates that the model fits are
similar, regardless of the number of loci included in the dataset.

Thus we can conclude that no harm is done by leaving in the ``fixed''
loci, and we proceed with the rest of our analyses using all of the
simulated loci.

\subsection{Model estimates}

\fig{anc-est-plot}{To diagnose dependence of model fit on selection
  state, we plot ancestral allele frequency estimates for each loci
  versus actual values from the simulation. Neutral loci are well
  estimated by the model, but loci under balancing and positive
  selection are not well estimated.}

\fig{gen-pop}{Number of generations and populations in the simulation
  affects model estimates ancestral allele frequency, agreeing with
  model expectations.}

\fig{notbeta}{Scatter plot matrix for various values of
  ancestral allele frequency $\pi$ for a simulated data set (actual
  simulated values indicated by row/column simulated). Models using
  priors that follow a $\beta(1,1)$ (indicated by fortranr1 and
  winbugs1) and $\beta(0.7,0.7)$ (fortran.old, fortranr0.7, and
  winbugs0.7) were fit using WinBUGS and our FORTRAN program. For
  alleles under positive selection, there are small discrepancies
  between the FORTRAN and WinBUGS programs.}

\fig[0.5]{c-over-time-all}{Lineplots of differentiation parameter
  estimates $c_j$ evolving over time. The model was fit for 4
  generations (50,100,150,200). Note the linear behavior of the model
  estimates, as expected. However, the slopes of the lines do not
  always match the expected theoretical slopes, which can be
  attributed to approximation errors.}


\subsection{Simulation summaries using animations}

\fig{sim-summary-plot}{The simulation summary diagnostic plot. Note
  how there is a time series plot for a single locus in the upper
  left. That same locus is highlighted with a circle in the upper
  right ancestral estimate plot, and with a vertical line in the
  bottom dotplot.}

To visualize 3 of the above simulation diagnostics at once, we made
combined plots of allele frequency time series, ancestral estimates,
and dotplots \autoref{sim-summary-plot}.

To visualize the influence of the number of generations on each of
these diagnostic plots, we used to the animation
package\cite{animation} to create a series of plots, one for each
generation. These images are put together and viewed in sequence to
form a statistical animation that reveals the dependence on the number
of generations. The animations can be viewed on the accompanying
website:

 \url{http://nicholsonppp.r-forge.r-project.org/}

\subsection{Prediction rates of the PPP-value classifier}

To evaluate the sensitivity and specificity of the PPP-value
classifier, we fit the model on 3 sets of 5 simulations with different
parameter values:

\begin{tabular}{rrr}
  Set & Populations & Loci \\
  \hline
  usual & 12 & 1000 \\ %  
  few populations & 4 & 1000\\   % few
  many neutral loci & 12 & 19999   % neu
\end{tabular}

For each of the above parameter sets, we fixed constant parameter
values of population size 1000 and 100 generations of evolution. Then
we did 5 different simulations with 100 loci each of
$s_i\in\{0.001,0.01,0.032,0.1,1\}$.

For each of these sets we first made density plots of PPP-value
conditional on selection state for each $s_i$ value
(\autoref{dens-several-s}, \autoref{dens-several-s-few},
\autoref{dens-several-s-neu}).  Then we evaluated false positive and
false negative rates for each possible decision rule; that is, each
possible cutoff for the PPP-value (\autoref{cutoff-plot},
\autoref{cutoff-plot-few}, \autoref{cutoff-plot-neu}).

\fig[0.8]{dens-several-s}{Density estimates for PPP-values of each
  selection state, given data sets simulated with different selection
  strengths $s_i$. Note how it gets easier to distinguish selection as
  the selection strength parameter increases.}

\fig[0.8]{dens-several-s-few}{Density estimates for PPP-values, for
  only 4 populations. With fewer populations it is more difficult to
  distinguish the behavior of loci under selection.}

\fig[0.8]{dens-several-s-neu}{Density estimates for PPP-values, when
  there is an abundance of neutral loci. In this case the densities
  are clearly distinguishable, but the sheer number of neutral loci
  makes a linear cutoff rule suboptimal.}

\fig[0.8]{cutoff-plot}{Note the optimal cutoffs are near 0.35,
  according to empirical risk minimzation.}

\fig[0.8]{cutoff-plot-few}{Note that optimal cutoffs are near 0.4,
  according to empirical risk minimization, but that only high
  selection values $s_i$ are detected. Best values for incorrect
  prediction are not as low as in the case where there are 12
  populations.}

\fig[0.8]{cutoff-plot-neu}{Note that with very many neutral alleles,
  the rate of false positives ascends very quickly. In this situation,
  the best cutoff value is around 0.2.}

ROCs were also traced, to compare all 15 simulations at the same time.

\fig{roc-desc}{ROCs for several selection strengths, neutral allele
  concentrations, and population numbers. As shown in the
  densityplots, increasing selection strengths $s_i$ tend to increase
  the area under the curve.}

\fig[0.8]{roc-s}{ROCs for several selection strengths, neutral allele
  concentrations, and population numbers. Note how the data sets with
  4 populations generate decision rules which are noticeably less
  powerful than those in the other 2 simulations.}

Additionally, ROCs were traced for 9 simulations comprising a cross of
3x3 parameter values: 25, 50, and 100 generations; 4, 8, 12
populations (\autoref{gen-pop-roc}).

\fig{gen-pop-roc}{ROCs show slight dependence of the PPP-value
  classifier on number of populations and generations. It is more
  difficult to accurately predict selection state for a smaller number
  of generations and populations. However, 8 and 12 populations seems
  to behave similarly, suggesting a threshhold for good behavior
  between 4 and 8.}

\section{Conclusions and future work}

More work needs to be done to characterize the expected number of
false positives and false negatives in a real dataset.

We should apply this model to a real dataset. It will be very easy
since the interface to the model uses R.

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
